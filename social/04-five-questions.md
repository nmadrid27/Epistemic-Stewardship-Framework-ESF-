---
title: "Five Questions That Take 60 Seconds"
platform: LinkedIn
topic: Five Questions
status: draft
posted-date:
word-count: ~300 (short) / ~380 (mid) / ~500 (long)
---

# Five Questions That Take 60 Seconds (DRAFT)

---

**Post Option A: Short-Form (Recommended for LinkedIn)**

Before you send, submit, or publish anything you made with AI, ask yourself five questions:

1. Can I defend this? Could I explain every claim to a colleague without referencing the AI's reasoning?
2. Is this mine? Does this reflect my actual position, or did I accept the AI's framing because it sounded reasonable?
3. Did I verify? Have I independently confirmed the facts, citations, and data?
4. Would I teach this? Am I prepared to stand behind this in a meeting, a classroom, or a review and respond to challenges?
5. Is my disclosure honest? Does it accurately represent who did what?

They take about 60 seconds. And question 2 is the one that catches me most often.

"Is this mine?" sounds simple. It isn't.

After working with AI on a draft, the line between "my position" and "a position I adopted because the AI stated it well" gets blurry fast. That's not a failure of intelligence. It's how fluent output works on your thinking.

These questions aren't a one-time checklist. In the epistemic stewardship framework I've been developing, they recur at every decision point.

The answers change as the work develops. "Is this mine?" after an outline means something different than "Is this mine?" after a full AI-assisted draft.

A "no" to any of them means stop and figure out why.

I've open-sourced the full framework, including how these questions fit into a broader workflow. Link in the first comment.

Which of these five would catch you?

---

*First comment: GitHub repo link*

*#EpistemicStewardship #AIinEducation #FutureOfWork #AILiteracy*

---

**Post Option B: Mid-Form**

Here are five questions I ask myself before I send, submit, or publish anything I've made with AI:

1. **Can I defend this?** Could I explain and justify every claim to a colleague, reviewer, or student without referencing the AI's reasoning?
2. **Is this mine?** Does this reflect my actual position, or did I passively accept the AI's framing because it sounded reasonable?
3. **Did I verify?** Have I independently confirmed factual claims, citations, and data points?
4. **Would I teach this?** Am I prepared to stand behind this in a classroom, boardroom, or review committee and respond to challenges?
5. **Is my disclosure honest?** Does my disclosure accurately represent the division of intellectual labor?

They take about 60 seconds. And I've found they change the entire relationship between me and the output.

Question 2 is the one that catches me most often.

"Is this mine?" sounds like it should be obvious. It isn't. After working with AI on a draft for an hour, the line between "my position" and "a position I adopted because the AI stated it clearly" gets blurry. That's not a failure of intelligence or attention. It's how fluent output works on your thinking.

The better the AI writes, the harder it is to remember what you were going to say before you read what it said.

This is why I don't treat these as a one-time checklist. In the epistemic stewardship framework I've been developing, they recur at every decision point. The answers change as the work develops. "Is this mine?" after a rough outline means something different than "Is this mine?" after a polished, AI-assisted draft. Asking the same question at different stages catches drift that a single review at the end would miss.

A "no" to any of these five means stop. Don't finalize. Figure out where the work stopped being yours and fix it.

I've open-sourced the full framework, including how these questions fit into a broader workflow. Link in the first comment.

Which of these five would catch you?

---

*First comment: GitHub repo link*

*#EpistemicStewardship #AIinEducation #FutureOfWork #AILiteracy*

---

**Post Option C: Long-Form**

Here are five questions I ask myself before I send, submit, or publish anything I've made with AI:

1. **Can I defend this?** Could I explain and justify every claim in this work to a colleague, reviewer, or student without referencing the AI's reasoning?
2. **Is this mine?** Does this reflect my actual position, or did I passively accept the AI's framing because it sounded reasonable?
3. **Did I verify?** Have I independently confirmed factual claims, citations, and data points?
4. **Would I teach this?** Am I prepared to stand behind this content in a classroom, boardroom, or review committee and respond to challenges?
5. **Is my disclosure honest?** Does my disclosure accurately represent the division of intellectual labor?

They take about 60 seconds. And I've found they change the entire relationship between me and the output.

---

Question 2 is the one that catches me most often.

"Is this mine?" sounds like it should be obvious. It isn't.

After working with AI on a draft for an hour, the line between "my position" and "a position I adopted because the AI stated it clearly" gets blurry. That's not a failure of intelligence or attention. It's how fluent output works on your thinking.

The better the AI writes, the harder it is to remember what you were going to say before you read what it said.

This is why I don't treat these as a one-time checklist. In the epistemic stewardship framework I've been developing, they recur at every decision point in the workflow.

The answers change as the work develops. "Is this mine?" after a rough outline means something different than "Is this mine?" after a polished, AI-assisted draft.

Asking the same question at different stages catches drift that a single review at the end would miss.

---

A "no" to any of these five means stop. Don't finalize. Figure out where the work stopped being yours and fix it.

I've been open-sourcing the full framework, including how these questions fit into a broader workflow for both practitioners and students. Link in the first comment.

Which of these five would catch you? I'm curious whether question 2 is as universally difficult as I think it is, or whether that's specific to my own weak spots.

---

*First comment: GitHub repo link*

*#EpistemicStewardship #AIinEducation #FutureOfWork #AILiteracy*
