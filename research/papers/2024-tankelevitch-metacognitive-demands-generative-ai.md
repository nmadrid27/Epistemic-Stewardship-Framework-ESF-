---
type: paper-summary
title: "The Metacognitive Demands and Opportunities of Generative AI"
authors: "Tankelevitch, L., Kewenig, V., Simkute, A., Scott, A., Sarkar, A., Sellen, A., & Rintel, S."
year: 2024
citation: "Tankelevitch, L., Kewenig, V., Simkute, A., Scott, A., Sarkar, A., Sellen, A., & Rintel, S. (2024). The metacognitive demands and opportunities of generative AI. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24). ACM."
doi: ""
url: ""
epistemic-status: peer-reviewed
esf-cluster: "B.2 Metacognition and Human Oversight"
date-added: 2026-02-19
processed: true
---

## Key Findings

- Effective oversight of AI output requires sustained metacognitive effort: monitoring one's own comprehension, detecting subtle departures from one's own understanding, and resisting the cognitive pull of fluent, well-structured text.
- Metacognitive demands of AI oversight are higher than most users expect; failures of metacognitive monitoring are common even among experienced professionals.
- The fluency and structural coherence of AI-generated output actively undermines the metacognitive vigilance required to detect when that output misrepresents the user's own position.

## ESF Relevance

Tankelevitch et al. provide the empirical foundation for ESF's Five Questions design: each question targets a specific metacognitive process that AI-assisted work requires but does not automatically trigger. Their finding that metacognitive effort is not self-sustaining motivates repeating the Five Questions at every gate rather than assuming a single application is sufficient. This is the CHI '24 Best Paper.
