---
type: paper-summary
title: "Regulation (EU) 2024/1689 (Artificial Intelligence Act), Article 14: Human Oversight"
authors: "European Union"
year: 2024
citation: "European Union. (2024). Regulation (EU) 2024/1689 (Artificial Intelligence Act), Article 14: Human oversight."
doi: ""
url: ""
epistemic-status: policy
esf-cluster: "B.2 Metacognition and Human Oversight"
date-added: 2026-02-19
processed: true
---

## Key Findings

- Codifies human oversight as a regulatory requirement for high-risk AI systems; oversight must be structural and verifiable, not merely aspirational.
- Requires that oversight mechanisms be designed into AI systems by their developers — accountability is built in, not added afterward.
- While targeting AI system designers rather than end users, the underlying logic is applicable to workflow design: oversight that is not structurally required tends not to occur.

## ESF Relevance

The EU AI Act's underlying logic mirrors ESF's approach at the workflow level: human oversight must be structural and verifiable. Where the Act requires oversight to be designed into AI systems, ESF requires oversight mechanisms to be designed into the workflows through which humans use those systems — the same principle applied one layer up in the accountability chain.
