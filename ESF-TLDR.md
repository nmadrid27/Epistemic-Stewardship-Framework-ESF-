---
title: "ESF; TLDR for Reviewers"
author: Nathan Madrid
date: 2026-02-19
type: overview
---

# Epistemic Stewardship Framework (ESF)

## The One-Sentence Version

ESF is a structured methodology for making sure that work produced with AI assistance genuinely belongs to the person responsible for it.

---

## The Problem

Universities currently have AI policies that say *whether* AI can be used. Nobody has a methodology for *how* to use it without losing intellectual ownership of the work.

Three specific failures:

1. **Ban-or-permit policies** regulate access but do not structure practice
2. **Student-only focus** ignores that faculty use AI too, often without any methodology
3. **Compliance framing** treats AI as an integrity problem instead of a knowledge-making problem

---

## Where ESF Came From

ESF was not derived from a literature review. It was built from practice.

Nathan Madrid developed the framework's core constructs (the Directive Memo, the Five Questions, Content Epistemic Weight, Human Validation Gates, and the phased workflow model) through his own operational practice integrating AI into curriculum development, assessment design, and institutional work at an art and design university. The methodology was refined through daily use across multiple courses and administrative contexts before it was ever formalized as a framework or positioned against the scholarly literature.

The literature review (31 sources across 8 research areas) was conducted after the constructs existed. It serves two purposes: confirming that the constructs address real, documented problems in the field, and identifying where the constructs fill gaps that existing frameworks leave open. The scholarship validates and grounds the framework. It does not originate it.

This distinction matters. ESF's constructs are practitioner-tested, not theoretically derived. The Directive Memo exists because Nathan found that without one, AI-assisted drafts drifted from his intent in ways that were difficult to detect after the fact. The Five Questions exist because he found that general "review your work" advice was insufficient. Specific, answerable questions at specific points in the workflow caught issues that open-ended reflection missed. The two-level architecture exists because applying a single process model to both his own professional work and his students' learning exposed a fundamental mismatch.

Every architectural decision in ESF traces back to a problem Nathan encountered and solved in practice. The scholarly grounding confirms these solutions are not idiosyncratic; they address challenges documented across the field. But the solutions came first.

---

## How ESF Works

ESF has two levels because faculty producing work and students learning through work are doing fundamentally different things.

### Level 1: For Faculty and Administrators

When you use AI to produce professional work (syllabi, reports, scholarship, assessments):

```
SCOPE → DIRECT → BUILD → VALIDATE → DISCLOSE
```

The key move: **Write a Directive Memo before you start.** This captures your position, emphasis, and non-negotiables *before* the AI offers its version. Then you have a standard to check against throughout.

### Level 2: For Students

When students use AI while learning:

```
INQUIRE → POSITION → EXPLORE → MAKE → REFLECT
```

The key move: **AI does not enter until Phase 3.** Students must articulate what they know and where they stand (Phases 1-2) before AI enters the process. This prevents the common pattern where students react to AI output instead of developing their own thinking first.

### The Connection

When a faculty member uses Level 1 to design an assignment, they are simultaneously designing the learning environment students work within at Level 2. Faculty who require epistemic discipline from students are practicing it themselves.

---

## The Five Questions

At every checkpoint, the person asks:

| Question | What It Tests |
|----------|--------------|
| **Can I defend this?** | Could I explain this without referencing what the AI said? |
| **Is this mine?** | Is this my thinking, or did I just accept what sounded good? |
| **Did I verify?** | Did I independently check facts, sources, and claims? |
| **Would I teach this?** | Could I stand behind this in front of colleagues or students? |
| **Is the disclosure honest?** | Does my statement about AI use accurately describe what happened? |

If any answer is "no," stop and fix it before continuing.

---

## Content Epistemic Weight

Not everything needs the full process. ESF scales to the stakes:

| Weight | Examples | What's Required |
|--------|----------|----------------|
| **High** | Scholarship, tenure materials, accreditation reports, exam questions | Full workflow: Directive Memo, all gates, Integrity Report |
| **Medium** | Syllabi, rubrics, assignment briefs, course proposals | Abbreviated memo, key gates, disclosure |
| **Low** | Emails, meeting agendas, formatting tasks | Light review, attribution |

---

## Seven Core Constructs

| Construct | Purpose |
|-----------|---------|
| **Directive Memo** | Captures your intellectual position before AI engagement |
| **Five Questions** | Recurring checkpoints that test ownership at every transition |
| **Content Epistemic Weight** | Determines how much process a given task requires |
| **Human Validation Gates** | Mandatory pause points where you verify before proceeding |
| **Phased Workflow** | Level 1 and Level 2 process models |
| **Disclosure Protocol** | Transparent documentation of the human-AI collaboration |
| **Framework Evolution Protocol** | Built-in mechanisms so the framework updates as AI evolves |

---

## Why Tool-Agnostic? The Case for Epistemic Rigor First

ESF deliberately does not recommend, require, or assume any specific AI tool, model, or platform. This is a design decision, not an oversight.

**The epistemic challenge is tool-independent.** The core problem ESF addresses (maintaining intellectual ownership when AI assists in producing work) occurs with every generative AI system. Tankelevitch et al. (2024) demonstrated that metacognitive failures (accepting AI output that subtly departs from your own position) occur regardless of which AI tool is used. Atchley et al. (2024) showed that cognitive automation (declining vigilance over time) is a property of repeated human-AI interaction, not of any specific tool. The Five Questions work whether you are using ChatGPT, Claude, Gemini, Copilot, or whatever emerges next year.

**Tool-specific frameworks have a shelf life. Epistemic skills do not.** The AI landscape turns over faster than institutional adoption cycles. A framework built around a specific tool becomes obsolete when that tool changes or is replaced. The capacity to write a clear Directive Memo, to detect when your position has drifted toward the AI's framing, to verify claims independently, and to disclose honestly: these are durable skills that transfer across any tool, any model generation, and any discipline. Zawacki-Richter et al. (2019) documented how each generation of AI-in-education made prior tool-specific approaches obsolete. Luksha et al. (2024) argue that educational methodologies must be designed for adaptation, not permanence.

**Prescribing tools undermines the agency ESF develops.** If a framework tells you which AI to use, it has made a decision that should be yours. ESF's epistemic weight model asks *you* to assess how much human authority your content demands. The Five Questions ask *you* to evaluate your relationship to the work. Selecting the right tool for the task is part of that intellectual responsibility, not something a framework should remove. This applies especially to students: choosing and evaluating tools is itself an epistemic practice.

**Institutional adoption requires flexibility.** Different departments use different tools. STEM faculty may use code-generation AI. Humanities faculty may use text-generation AI. Design faculty may use image-generation AI. Administrative offices may use enterprise platforms. A framework that works across all of these contexts can be adopted institution-wide. One that assumes a specific tool cannot.

**What matters is the human's relationship to the work, not the tool that helped produce it.** Clark and Chalmers (1998) established that cognitive tools become legitimate extensions of thinking when the human actively endorses their contributions. The endorsement condition (the foundation of the Directive Memo) applies to any tool. The question is never "which AI did you use?" The question is "can you defend this as yours?"

---

## What ESF Is Not

- **Not a restriction tool.** It structures AI use to preserve ownership, not to limit it.
- **Not a replacement** for existing frameworks. ESF works alongside AIAS, AID, and institutional policies.
- **Not static.** It includes built-in mechanisms for revision as AI and research evolve.

---

## Getting Started

**Individual:** Write one Directive Memo before your next AI-assisted task. Apply the Five Questions after one draft. Scale from there.

**Department:** 5-10 faculty across disciplines, one term pilot, shared learning sessions.

**Institution:** Policy integration, student orientation, assessment rubrics, accreditation alignment.

---

## Scholarly Basis

ESF is grounded in 31 verified sources across 8 research areas, including epistemic agency theory, metacognition research, scaffolded learning, and iterative design methodology. Full citations in the Literature Review.

---

> **AI Disclosure:** This overview document was developed through human-AI collaboration. Nathan Madrid established the framework's constructs, arguments, and architecture from his operational practice. AI assisted with organizing and drafting this summary from the full ESF Framework Document and supporting deliverables. All intellectual claims, the tool-agnostic rationale, and the practice-first provenance narrative reflect the author's position and experience. The scholarly sources cited have been verified to the standards documented in the ESF Research Summary.

---

*Epistemic Stewardship Framework | Nathan Madrid | 2026*
*Developed from operational practice in higher education*
