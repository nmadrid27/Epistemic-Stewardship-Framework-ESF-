# AI-201 — Project 2: Responsive System

**Assigned:** Week 4
**Due:** Week 7, Friday — live demo + process documentation

---

## Brief

Build an interactive system that responds to real-time input and generates visual, sonic, or data output. The system must have at least one emergent behavior — something that arises from the interaction between components rather than being explicitly programmed.

You choose the tools, the input source, and the output medium. What matters is that the system is genuinely responsive: the output changes meaningfully based on what the user (or environment) does.

---

## Requirements

**The system must:**
- Accept real-time input (mouse, keyboard, camera, microphone, sensor data, API feed, or other)
- Generate output that changes based on input state
- Include at least one behavior the user can discover — something not immediately obvious from the interface

**Your documentation must include:**
- Design Intent (written before significant AI engagement)
- 3 Records of Resistance documenting deliberate choices about AI output
- A process blog with kept/revised/rejected entries at each major decision point
- A 2–3 minute demo video

---

## Evaluation

Projects will be assessed on:
- Responsiveness: does the system behave differently in interesting ways based on input?
- Emergence: is there something to discover?
- Process integrity: does your documentation show your thinking, not just your outcome?
- Execution: does it run without crashing during the demo?

---

## Notes

Tool selection is yours. You are not required to use any specific library, framework, or language. If you are uncertain whether a tool is appropriate, your responsibility is to research it and make a case — not to ask for permission.

AI tools may be used as research subjects and thinking partners throughout the project. They may not originate your Design Intent or make core technical decisions on your behalf without documentation.
